{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime\n",
    "def make_series():\n",
    "    time_start = datetime.datetime.strptime('20:00:00', '%H:%M:%S')\n",
    "    time_end = datetime.datetime.strptime('21:00:00', '%H:%M:%S')\n",
    "    time_list = []\n",
    "    i = time_start \n",
    "    \n",
    "    while(i<time_end):\n",
    "        time_list.append(i.time())\n",
    "        i = i + datetime.timedelta(seconds = 1)\n",
    "    samples  = pd.Series(np.random.normal(loc=0, scale=1, size=3600))\n",
    "    time_list = pd.Series(time_list)\n",
    "    \n",
    "    columns = ['Time','Value']\n",
    "    final_df = pd.DataFrame({columns[0]:time_list, columns[1]:samples})\n",
    "    final_df.set_index(time_list)\n",
    "    return final_df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Time     Value\n",
      "0     20:00:00  1.042719\n",
      "1     20:00:01  1.520273\n",
      "2     20:00:02 -0.926367\n",
      "3     20:00:03 -0.689720\n",
      "4     20:00:04 -0.328922\n",
      "...        ...       ...\n",
      "3595  20:59:55  0.556572\n",
      "3596  20:59:56  0.408466\n",
      "3597  20:59:57  1.238654\n",
      "3598  20:59:58 -1.129875\n",
      "3599  20:59:59  0.204169\n",
      "\n",
      "[3600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = []\n",
    "for i in range(50):\n",
    "    inserter = make_series()\n",
    "    X.append(inserter)\n",
    "\n",
    "print((X[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def preproscessing(df):\n",
    "    time_series_data  = df['Value'].values\n",
    "    time_series_data = time_series_data.reshape(-1,1)\n",
    "    model = MinMaxScaler()\n",
    "    scaled_data = model.fit_transform(time_series_data)\n",
    "    scaled_data = scaled_data.flatten()\n",
    "    df['Nomalized_values'] = pd.Series(scaled_data)\n",
    "    df.drop('Value',axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Time     Value  Nomalized_values\n",
      "0     20:00:00 -0.039851          0.499838\n",
      "1     20:00:01 -1.071868          0.358512\n",
      "2     20:00:02  0.098586          0.518796\n",
      "3     20:00:03  0.014855          0.507329\n",
      "4     20:00:04  0.227979          0.536515\n",
      "...        ...       ...               ...\n",
      "3595  20:59:55 -2.044915          0.225262\n",
      "3596  20:59:56  0.156631          0.526744\n",
      "3597  20:59:57 -1.562380          0.291340\n",
      "3598  20:59:58 -1.736225          0.267534\n",
      "3599  20:59:59 -0.895137          0.382714\n",
      "\n",
      "[3600 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in X: \n",
    "    preproscessing(i)\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making of quantum machine learning model \n",
    "import pennylane as qml\n",
    "from pennylane.optimize import GradientDescentOptimizer\n",
    "dev = qml.device('lightning.qubit',wires = 2)\n",
    "#wires = 2 qubits ciruits \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def my_circuit(params):\n",
    "    qml.RY(params,wires = 0)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#angel encoding \n",
    "#given classical LSTM work on classical data, we first angle encoode the classical data and then find the expectation values as the input for the network\n",
    "for dataset in X: \n",
    "    dataset['Exp_val'] = dataset['Nomalized_values'].apply(my_circuit)\n",
    "    dataset.drop('Nomalized_values',axis = 1)\n",
    "    \n",
    " \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Time   Exp_val\n",
      "0     20:00:00  0.806096\n",
      "1     20:00:01  0.763520\n",
      "2     20:00:02  0.939481\n",
      "3     20:00:03  0.927262\n",
      "4     20:00:04  0.906563\n",
      "...        ...       ...\n",
      "3595  20:59:55  0.845521\n",
      "3596  20:59:56  0.856717\n",
      "3597  20:59:57  0.789077\n",
      "3598  20:59:58  0.949118\n",
      "3599  20:59:59  0.871520\n",
      "\n",
      "[3600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data,seq_length):\n",
    "    x,y = [], []\n",
    "    df_as_np = data.to_numpy()\n",
    "    for i in range(len(data)-seq_length):\n",
    "        row =  [[a] for a in df_as_np[i:i+seq_length]]\n",
    "        x.append(row)\n",
    "        label = df_as_np[i+5]\n",
    "        y.append(label)\n",
    "    return np.array(x),np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3595, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.4750 - val_loss: 0.0049\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0045\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import LSTM, Dense \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(8,return_sequences=True, input_shape = (5,1)))\n",
    "model.add(LSTM(8))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer = 'adam',loss = 'mse' )\n",
    "\n",
    "for dataset in X[0:1]: \n",
    "    x,y = create_sequences(dataset['Exp_val'],5)\n",
    "    x_train, x_test_1, y_train, y_test_1 = train_test_split(x,y,test_size = 0.2,random_state = 42)\n",
    "    model.fit(x,y,epochs = 10,validation_data = (x_test_1,y_test_1),batch_size=32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating output datasets \n",
    "time_start = datetime.datetime.strptime('21:00:00', '%H:%M:%S')\n",
    "time_end = datetime.datetime.strptime('21:03:00', '%H:%M:%S')\n",
    "time_list = []\n",
    "i = time_start \n",
    "    \n",
    "while(i<time_end):\n",
    "    time_list.append(i.time())\n",
    "    i = i + datetime.timedelta(seconds = 1)\n",
    "samples  = pd.Series(np.random.normal(loc=0, scale=1, size=180))\n",
    "time_list = pd.Series(time_list)\n",
    "    \n",
    "columns = ['Time','Value']\n",
    "final_df_a = pd.DataFrame({columns[0]:time_list, columns[1]:samples})\n",
    "final_df_a.set_index(time_list)\n",
    "preproscessing(final_df_a)\n",
    "final_df_a['Exp_val'] = final_df_a['Nomalized_values'].apply(my_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = create_sequences(final_df_a['Exp_val'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "      Value  predictions\n",
      "0  0.925492     0.882901\n",
      "1  0.929842     0.881585\n",
      "2  0.870871     0.862803\n",
      "3  0.888258     0.877586\n",
      "4  0.889837     0.892171\n",
      "5  0.779904     0.893048\n",
      "6  0.886770     0.878267\n",
      "7  0.977109     0.881125\n",
      "8  0.792095     0.866286\n",
      "9  0.920129     0.887514\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(x_test_1)\n",
    "\n",
    "predictions = predictions.reshape(719)\n",
    "time_start = datetime.datetime.strptime('21:00:00', '%H:%M:%S')\n",
    "time_end = datetime.datetime.strptime('21:03:00', '%H:%M:%S')\n",
    "time_list_a = []\n",
    "i = time_start \n",
    "    \n",
    "\n",
    "final_df_a = pd.DataFrame({'Value':y_test_1, 'predictions': predictions})\n",
    "print(final_df_a.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from itertools import cycle \n",
    "import matplotlib.pyplot as plt \n",
    "import pennylane as qml \n",
    "from itertools import combinations\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "import random \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(sigma, contraction_hyperparameter):\n",
    "    prefac = 1/(np.pi)\n",
    "    sum_terms = tf.math.atan(2*np.pi*contraction_hyperparameter*tf.abs(sigma))\n",
    "    mean = np.mean(sum_terms)\n",
    "    return prefac*mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2527986809360291\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.4210 - val_loss: 0.0048\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0054\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "hyper_parameters = np.array([0.5,0.9,0.2,0.5,0.6])\n",
    "sigma = np.array([0.9,-0.1,-0.4,0.5,0.25])\n",
    "model = Sequential()\n",
    "model.add(LSTM(8,return_sequences=True, input_shape = (5,1)))\n",
    "model.add(LSTM(8))\n",
    "model.add(Dense(1))\n",
    "time_series_loss = 0.0045\n",
    "model.compile(optimizer = 'adam',loss = 'mse' )\n",
    "scores = []\n",
    "print(penalty(sigma,hyper_parameters))\n",
    "for dataset in X: \n",
    "    x,y = create_sequences(dataset['Exp_val'],5)\n",
    "    x_train, x_test_1, y_train, y_test_1 = train_test_split(x,y,test_size = 0.2,random_state = 42)\n",
    "    history= model.fit(x,y,epochs = 10,validation_data = (x_test_1,y_test_1),batch_size=32)\n",
    "    train_loss = np.mean(history.history['loss'])\n",
    "    \n",
    "    penalty_1 = penalty(sigma,hyper_parameters)\n",
    "    anomaly = abs(2*train_loss-2*penalty_1-time_series_loss)\n",
    "    time_series_loss = train_loss\n",
    "    scores.append(time_series_loss)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x224d8b59210>]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.array([i for i in range(len(scores))])\n",
    "plt.plot(a,scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
