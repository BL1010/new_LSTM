{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making input data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime\n",
    "def make_series():\n",
    "    time_start = datetime.datetime.strptime('20:00:00', '%H:%M:%S')\n",
    "    time_end = datetime.datetime.strptime('20:00:50', '%H:%M:%S')\n",
    "    time_list = []\n",
    "    i = time_start \n",
    "    \n",
    "    while(i<time_end):\n",
    "        time_list.append(i.time())\n",
    "        i = i + datetime.timedelta(seconds = 1)\n",
    "    samples  = pd.Series(np.random.normal(loc=0, scale=1, size=50))\n",
    "    time_list = pd.Series(time_list)\n",
    "    \n",
    "    columns = ['Time','Value']\n",
    "    final_df = pd.DataFrame({columns[0]:time_list, columns[1]:samples})\n",
    "    final_df.set_index(time_list)\n",
    "    return final_df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = []\n",
    "for i in range(50):\n",
    "    inserter = make_series()\n",
    "    X.append(inserter)\n",
    "\n",
    "print((X[0]['Value'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create sequences to be fed to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data,seq_length):\n",
    "    x,y = [], []\n",
    "    df_as_np = data.to_numpy()\n",
    "    for i in range(len(data)-seq_length):\n",
    "        row =  [[a] for a in df_as_np[i:i+seq_length]]\n",
    "        x.append(row)\n",
    "        label = df_as_np[i+5]\n",
    "        y.append(label)\n",
    "    return np.array(x),np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss calculater "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_value(true_values, predicted_values):\n",
    "    error = 0\n",
    "    for i in range(len(true_values)): \n",
    "        error = (true_values[i]-predicted_values[i])**2 + error \n",
    "    mean = error / len(true_values)\n",
    "    error = np.sqrt(mean)\n",
    "    return error\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import LSTM, Dense \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,return_sequences=True, input_shape = (5,1)))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer = 'adam',loss = 'mse' )\n",
    "\n",
    "for dataset in X: \n",
    "    x,y = create_sequences(dataset['Value'],5)\n",
    "    x_train, x_test_1, y_train, y_test_1 = train_test_split(x,y,test_size = 0.2,random_state = 42)\n",
    "    model.fit(x,y,epochs = 10,validation_data = (x_test_1,y_test_1),batch_size=32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making of test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "F = []\n",
    "for i in range(50):\n",
    "    inserter = make_series()\n",
    "    F.append(inserter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = []\n",
    "for i in range(50):\n",
    "    inserter = make_series()\n",
    "    G.append(inserter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = []\n",
    "for i in range(50):\n",
    "    inserter = make_series()\n",
    "    H.append(inserter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding anomolus spikes at random places in datasets \n",
    "\n",
    "for i in G: \n",
    "   \n",
    "    min = 2\n",
    "    max = 1\n",
    "    for j in range(random.randint(1,49)):\n",
    "        index_number = random.randint(1,49)\n",
    "        addend = min + (max-min)*random.random()\n",
    "        \n",
    "        i['Value'][index_number]+= addend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in H: \n",
    "    for j in range(50):\n",
    "        i['Value'][j] += np.sin(j)\n",
    "   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(sigma, contraction_hyperparameter):\n",
    "    prefac = 1/(np.pi)\n",
    "    sum_terms = tf.math.atan(2*np.pi*contraction_hyperparameter*tf.abs(sigma))\n",
    "    mean = np.mean(sum_terms)\n",
    "    return prefac*mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING AND RECORDING OBSERVATIONS FOR F\n",
    "\n",
    "x,y = create_sequences(F[0]['Value'],5)\n",
    "y_predict = model.predict(x)\n",
    "y_predict  = y_predict.reshape(y.shape)\n",
    "c_0 = loss_value(y,y_predict)\n",
    "\n",
    "c_1 = c_0\n",
    "\n",
    "# container for storing anomolus scores \n",
    "scores_array = []\n",
    "\n",
    "sigma = np.array([0.9,0.25,0.1,-0.5,0.80,0.23])\n",
    "hyper_parameters = np.array([0.1,0.25,0.31,0.45,0.22,0.4])\n",
    "\n",
    "\n",
    "score_array= abs(2*c_0 - 2*penalty(sigma,hyper_parameters)-c_1)\n",
    "scores_array.append(score_array)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in F[1:]:\n",
    "    x,y = create_sequences(i['Value'],5)\n",
    "    y_predict = model.predict(x)\n",
    "    y_predict  = y_predict.reshape(y.shape)\n",
    "    c_0 = loss_value(y,y_predict)\n",
    "    score_array= abs(2*c_0 - 2*penalty(sigma,hyper_parameters)-c_1)\n",
    "    c_1 = c_0\n",
    "    scores_array.append(score_array)\n",
    "print(len(scores_array))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING AND RECORDING OBSERVATIONS FOR G\n",
    "\n",
    "# container for storing anomolous scores \n",
    "scores_array_g = []\n",
    "x,y = create_sequences(G[0]['Value'],5)\n",
    "y_predict = model.predict(x)\n",
    "y_predict  = y_predict.reshape(y.shape)\n",
    "c_0 = loss_value(y,y_predict)\n",
    "\n",
    "c_1 = c_0\n",
    "\n",
    "sigma = np.array([0.9,0.25,0.1,-0.5,0.80,0.23])\n",
    "hyper_parameters = np.array([0.1,0.25,0.31,0.45,0.22,0.4])\n",
    "\n",
    "\n",
    "score_array= abs(2*c_0 - 2*penalty(sigma,hyper_parameters)-c_1)\n",
    "scores_array_g.append(score_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in G[1:]:\n",
    "    x,y = create_sequences(i['Value'],5)\n",
    "    y_predict = model.predict(x)\n",
    "    y_predict  = y_predict.reshape(y.shape)\n",
    "    c_0 = loss_value(y,y_predict)\n",
    "    score_array= abs(2*c_0 - 2*penalty(sigma,hyper_parameters)-c_1)\n",
    "    c_1 = c_0\n",
    "    scores_array_g.append(score_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING AND RECORDING OBSERVATIONS FOR H\n",
    "\n",
    "#container for anomolous scores \n",
    "scores_array_h = []\n",
    "x,y = create_sequences(H[0]['Value'],5)\n",
    "y_predict = model.predict(x)\n",
    "y_predict  = y_predict.reshape(y.shape)\n",
    "c_0 = loss_value(y,y_predict)\n",
    "\n",
    "c_1 = c_0\n",
    "\n",
    "sigma = np.array([0.9,0.25,0.1,-0.5,0.80,0.23])\n",
    "hyper_parameters = np.array([0.1,0.25,0.31,0.45,0.22,0.4])\n",
    "\n",
    "\n",
    "score_array= abs(2*c_0 - 2*penalty(sigma,hyper_parameters)-c_1)\n",
    "scores_array_h.append(score_array)\n",
    "\n",
    "for i in H[1:]:\n",
    "    x,y = create_sequences(i['Value'],5)\n",
    "    y_predict = model.predict(x)\n",
    "    y_predict  = y_predict.reshape(y.shape)\n",
    "    c_0 = loss_value(y,y_predict)\n",
    "    score_array= abs(2*c_0 - 2*penalty(sigma,hyper_parameters)-c_1)\n",
    "    c_1 = c_0\n",
    "    scores_array_h.append(score_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
